
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: docs/nn_relu.ipynb

import sys
from pathlib import Path
sys.path.append(Path.cwd().parent.as_posix())
from nn.neural import Neural

class Relu(Neural):
    def __repr__(self): return "Relu()"
    def forward(self, inp): return inp.clamp_min(0.)-0.5
    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g